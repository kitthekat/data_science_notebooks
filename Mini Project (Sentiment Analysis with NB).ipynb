{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP-4448\n",
    "\n",
    "#### Christopher Kramer\n",
    "#### 2021-02-18\n",
    "## Sentiment Analysis with NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "from typing import Union\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Find some text data of your own choice, it could be labelled tweets, etc. \n",
    "Your dataset should have at least 200 instances, and if there are several columns of text, you can choose to merge the text columns into a single text column. Each text instance should have at least 60 words. \n",
    "Clean the data, split the data, transform the data to a representation suitable for your algorithm, build your model and evaluate the model. Tune some parameters of interest and write a short report about what problem your mini project is trying to address, the description of your data, the choice of algorithm used, the performance of your algorithm, overfitting, the choice of hyperparameters tunned, then your recommendation or conclusion (imagine you were trying to recommend this algorithm to a stakeholder, and you need this report to include important and persuasive elements). Your report could be in one or two paragraphs and should include relevant code and output at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment of tweets concerning the global pandemic could be a useful tool in understanding the public reaction to government rollout of vaccines, etc.\n",
    "\n",
    "Is it possible to reliably predict the sentiment of a Corona Virus tweet on a 5-point scale using a Multinomial Naive Bayes classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pd.read_csv('Corona_NLP_train.csv'), pd.read_csv('Corona_NLP_test.csv')], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15812</th>\n",
       "      <td>19611</td>\n",
       "      <td>64563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22-03-2020</td>\n",
       "      <td>I am loving these COVID-19  gas prices! It's b...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43951</th>\n",
       "      <td>2795</td>\n",
       "      <td>47747</td>\n",
       "      <td>Correct Time Zone</td>\n",
       "      <td>14-03-2020</td>\n",
       "      <td>BEING NEIGHBORLY IN A TIME OF COVID-19 ? \\r\\r\\...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37952</th>\n",
       "      <td>41751</td>\n",
       "      <td>86703</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>11-04-2020</td>\n",
       "      <td>The Consumer in the Age of Corona Virus - how ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35910</th>\n",
       "      <td>39709</td>\n",
       "      <td>84661</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>09-04-2020</td>\n",
       "      <td>Dairy farmers reserves are tapped out after y...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39494</th>\n",
       "      <td>43293</td>\n",
       "      <td>88245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>@WAGSocialCare @WAGSocialCare your Walgreens w...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName           Location     TweetAt  \\\n",
       "15812     19611       64563                NaN  22-03-2020   \n",
       "43951      2795       47747  Correct Time Zone  14-03-2020   \n",
       "37952     41751       86703       Portland, OR  11-04-2020   \n",
       "35910     39709       84661      Cambridge, MA  09-04-2020   \n",
       "39494     43293       88245                NaN  13-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "15812  I am loving these COVID-19  gas prices! It's b...            Positive  \n",
       "43951  BEING NEIGHBORLY IN A TIME OF COVID-19 ? \\r\\r\\...            Positive  \n",
       "37952  The Consumer in the Age of Corona Virus - how ...             Neutral  \n",
       "35910  Dairy farmers reserves are tapped out after y...            Negative  \n",
       "39494  @WAGSocialCare @WAGSocialCare your Walgreens w...  Extremely Positive  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n",
       "       'Extremely Positive'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName          int64\n",
       "ScreenName        int64\n",
       "Location         object\n",
       "TweetAt          object\n",
       "OriginalTweet    object\n",
       "Sentiment        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet text will be the primary feature used in analysis.\n",
    "\n",
    "Time data will also be captured as a feature to include in the model. Individuals may be more or less positive depending on the time of day, and days into the pandemic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TweetAt'] = pd.to_datetime(data['TweetAt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['daysago'] = pd.Timestamp.now() - data['TweetAt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>daysago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44950</th>\n",
       "      <td>3794</td>\n",
       "      <td>48746</td>\n",
       "      <td>Israel ??</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44951</th>\n",
       "      <td>3795</td>\n",
       "      <td>48747</td>\n",
       "      <td>Farmington, NM</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44952</th>\n",
       "      <td>3796</td>\n",
       "      <td>48748</td>\n",
       "      <td>Haverford, PA</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44953</th>\n",
       "      <td>3797</td>\n",
       "      <td>48749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44954</th>\n",
       "      <td>3798</td>\n",
       "      <td>48750</td>\n",
       "      <td>Arlington, Virginia</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>343 days 17:06:40.468433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44955 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName             Location    TweetAt  \\\n",
       "0          3799       48751               London 2020-03-16   \n",
       "1          3800       48752                   UK 2020-03-16   \n",
       "2          3801       48753            Vagabonds 2020-03-16   \n",
       "3          3802       48754                  NaN 2020-03-16   \n",
       "4          3803       48755                  NaN 2020-03-16   \n",
       "...         ...         ...                  ...        ...   \n",
       "44950      3794       48746            Israel ?? 2020-03-16   \n",
       "44951      3795       48747       Farmington, NM 2020-03-16   \n",
       "44952      3796       48748        Haverford, PA 2020-03-16   \n",
       "44953      3797       48749                  NaN 2020-03-16   \n",
       "44954      3798       48750  Arlington, Virginia 2020-03-16   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \\\n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1      advice Talk to your neighbours family to excha...            Positive   \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3      My food stock is not the only one which is emp...            Positive   \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "...                                                  ...                 ...   \n",
       "44950  Meanwhile In A Supermarket in Israel -- People...            Positive   \n",
       "44951  Did you panic buy a lot of non-perishable item...            Negative   \n",
       "44952  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral   \n",
       "44953  Gov need to do somethings instead of biar je r...  Extremely Negative   \n",
       "44954  I and @ForestandPaper members are committed to...  Extremely Positive   \n",
       "\n",
       "                       daysago  \n",
       "0     343 days 17:06:40.468433  \n",
       "1     343 days 17:06:40.468433  \n",
       "2     343 days 17:06:40.468433  \n",
       "3     343 days 17:06:40.468433  \n",
       "4     343 days 17:06:40.468433  \n",
       "...                        ...  \n",
       "44950 343 days 17:06:40.468433  \n",
       "44951 343 days 17:06:40.468433  \n",
       "44952 343 days 17:06:40.468433  \n",
       "44953 343 days 17:06:40.468433  \n",
       "44954 343 days 17:06:40.468433  \n",
       "\n",
       "[44955 rows x 7 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the use of time of day/days from today as features is not feasible. The tweets do not contain HH:MM data and are sourced entirely from a single day, so time features will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['OriginalTweet', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-105-34ed8e8d8b28>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['OriginalTweet'] = data['OriginalTweet'].apply(lambda x: clean_string(x, 5))\n"
     ]
    }
   ],
   "source": [
    "data['OriginalTweet'] = data['OriginalTweet'].apply(lambda x: clean_string(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['OriginalTweet'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['OriginalTweet']\n",
    "y = data['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents = 'ascii', lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5321528148543632"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, multi_clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36777006584801564"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, multi_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is overfit and does not generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying tune-sklearn which is supposed to be faster than built-in tuners. \n",
    "from tune_sklearn import TuneSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset takes a long time to train, so I've limited my choices and number of folds\n",
    "params = {\n",
    "    'alpha': list(np.logspace(0,9,num=50, endpoint=True)),\n",
    "    'fit_prior': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below can be replaced with \"GridSearchCV\" for classic tuning\n",
    "grid = TuneSearchCV(multi_clf, params, n_jobs=10, verbose=1, cv=5, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 17.5/31.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0.0/1 GPUs, 0.0/9.33 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: C:\\Users\\KittheKat\\ray_results\\_Trainable_2021-02-22_17-06-58<br>Number of trials: 10/10 (10 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=43648)\u001b[0m Windows fatal exception: access violation\n",
      "\u001b[2m\u001b[36m(pid=43648)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TuneSearchCV(cv=5, estimator=MultinomialNB(),\n",
       "             loggers=[<class 'ray.tune.logger.JsonLogger'>,\n",
       "                      <class 'ray.tune.logger.CSVLogger'>],\n",
       "             n_jobs=10,\n",
       "             param_distributions={'alpha': [1.0, 1.5264179671752336,\n",
       "                                            2.329951810515372,\n",
       "                                            3.5564803062231296,\n",
       "                                            5.428675439323861,\n",
       "                                            8.286427728546844,\n",
       "                                            12.648552168552964,\n",
       "                                            19.306977288832506,\n",
       "                                            29.470517025518113,\n",
       "                                            44.98432668969446,\n",
       "                                            68.66488450043...\n",
       "                                            2023.5896477251576,\n",
       "                                            3088.8435964774817,\n",
       "                                            4714.866363457394,\n",
       "                                            7196.856730011521,\n",
       "                                            10985.411419875594,\n",
       "                                            16768.3293681101,\n",
       "                                            25595.479226995383,\n",
       "                                            39069.39937054621,\n",
       "                                            59636.23316594649,\n",
       "                                            91029.81779915227,\n",
       "                                            138949.5494373139,\n",
       "                                            212095.08879201926, ...],\n",
       "                                  'fit_prior': [True, False]},\n",
       "             scoring={'score': <function _passthrough_scorer at 0x000002012E2F44C0>},\n",
       "             sk_n_jobs=1, use_gpu=True, verbose=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.5264179671752336, 'fit_prior': False}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38654573627955163"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_multi = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-tuning scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5950940262205612"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, best_multi.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4003381384588005"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, best_multi.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While hyperparameter tuning did boost performance, it did not seem to significantly improve overfitting, a common issue in NLP.\n",
    "\n",
    "I suspect this problem may require a more complex model to solve. That, or more nuanced text preprocessing (Tweets are tricky to work with).\n",
    "\n",
    "I would recommend utilizing a different model family for this usecase, potentially DNN with LSTM.\n",
    "\n",
    "It may be possible to layer binomial classifiers to improve performance:\n",
    "\n",
    "           Is sentiment positive?\n",
    "                /    \\\n",
    "              /       \\\n",
    "            /          \\\n",
    "Yes - how positive?       No - how negative?\n",
    "\n",
    "           /\\             /\\\n",
    "           1 2           3  4\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
